{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n",
        "import time\n"
      ],
      "metadata": {
        "id": "k9Usztx11IXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Node:\n",
        "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None):\n",
        "        self.feature = feature\n",
        "        self.threshold = threshold\n",
        "        self.left = left\n",
        "        self.right = right\n",
        "        self.value = value\n",
        "\n",
        "class DecisionTree:\n",
        "    def __init__(self, max_depth=None):\n",
        "        self.max_depth = max_depth\n",
        "        self.root = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.root = self._grow_tree(X, y)\n",
        "\n",
        "    def _grow_tree(self, X, y, depth=0):\n",
        "        num_samples, num_features = X.shape\n",
        "        unique_labels = np.unique(y)\n",
        "\n",
        "        if len(unique_labels) == 1 or (self.max_depth and depth >= self.max_depth):\n",
        "            leaf_value = self._most_common_label(y)\n",
        "            return Node(value=leaf_value)\n",
        "\n",
        "        best_feature, best_threshold = self._best_split(X, y, num_features)\n",
        "\n",
        "        if best_feature is None:\n",
        "            return Node(value=self._most_common_label(y))\n",
        "\n",
        "        left_indices = X[:, best_feature] <= best_threshold\n",
        "        right_indices = ~left_indices\n",
        "\n",
        "        left_subtree = self._grow_tree(X[left_indices], y[left_indices], depth + 1)\n",
        "        right_subtree = self._grow_tree(X[right_indices], y[right_indices], depth + 1)\n",
        "\n",
        "        return Node(best_feature, best_threshold, left_subtree, right_subtree)\n",
        "\n",
        "    def _best_split(self, X, y, num_features):\n",
        "        best_entropy = float('inf')\n",
        "        best_feature, best_threshold = None, None\n",
        "\n",
        "        for feature in range(num_features):\n",
        "            thresholds = np.unique(X[:, feature])\n",
        "            for threshold in thresholds:\n",
        "                entropy = self._entropy_impurity(X[:, feature], y, threshold)\n",
        "                if entropy < best_entropy:\n",
        "                    best_entropy = entropy\n",
        "                    best_feature = feature\n",
        "                    best_threshold = threshold\n",
        "\n",
        "        return best_feature, best_threshold\n",
        "\n",
        "    def _entropy_impurity(self, feature_column, y, threshold):\n",
        "        left_indices = feature_column <= threshold\n",
        "        right_indices = ~left_indices\n",
        "\n",
        "        left_entropy = self._entropy(y[left_indices])\n",
        "        right_entropy = self._entropy(y[right_indices])\n",
        "\n",
        "        left_weight = np.sum(left_indices) / len(y)\n",
        "        right_weight = np.sum(right_indices) / len(y)\n",
        "\n",
        "        return left_weight * left_entropy + right_weight * right_entropy\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        _, counts = np.unique(y, return_counts=True)\n",
        "        probabilities = counts / counts.sum()\n",
        "        return -np.sum(probabilities * np.log2(probabilities + 1e-9))\n",
        "\n",
        "    def _most_common_label(self, y):\n",
        "        values, counts = np.unique(y, return_counts=True)\n",
        "        return values[np.argmax(counts)]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.array([self._traverse_tree(x, self.root) for x in X])\n",
        "\n",
        "    def _traverse_tree(self, x, node):\n",
        "        if node.value is not None:\n",
        "            return node.value\n",
        "\n",
        "        if x[node.feature] <= node.threshold:\n",
        "            return self._traverse_tree(x, node.left)\n",
        "        else:\n",
        "            return self._traverse_tree(x, node.right)\n"
      ],
      "metadata": {
        "id": "iXUnVCoo1IOR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d32y6ZMQ1DSS",
        "outputId": "f45d7b79-2482-4fbc-ec59-9d04688d4b2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('kddcup.data_10_percent.gz', <http.client.HTTPMessage at 0x7d337a42ad90>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Download dataset\n",
        "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
        "filename = \"kddcup.data_10_percent.gz\"\n",
        "urlretrieve(url, filename)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Data\n",
        "# Setting column names from dataset description\n",
        "columns = [\n",
        "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
        "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
        "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
        "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
        "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
        "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
        "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
        "]\n",
        "\n",
        "# Loading dataset in dataframe using pandas\n",
        "df = pd.read_csv(filename, names=columns)\n",
        "\n",
        "# Convert categorical columns using Label Encoding\n",
        "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
        "encoder = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Converting labels to binary, ie, 0 if normal and 1 if attack\n",
        "df[\"label\"] = df[\"label\"].apply(lambda x: 0 if x == \"normal.\" else 1)\n",
        "\n",
        "X = df.drop(\"label\", axis=1).values # Extracting features\n",
        "y = df[\"label\"].values #Extracting labels\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# 80% train, 20% test dataset split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "oVBbfbYx1Pj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and evaluate the Decision Tree model\n",
        "dt = DecisionTree(max_depth=4)\n",
        "dt.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = dt.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = np.mean(y_pred == y_test) * 100\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWkuTlI41YKa",
        "outputId": "3c51a51d-e973-4ea3-84a3-25ef30c7b6e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 99.66%\n"
          ]
        }
      ]
    }
  ]
}