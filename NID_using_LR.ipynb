{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "IL3sTaBsTnlW"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from urllib.request import urlretrieve\n",
        "from tqdm import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class LogisticRegression:\n",
        "    def __init__(self, alpha=0.01, epochs=1000):\n",
        "        self.alpha= alpha #Alpha is the learning rate\n",
        "        self.epochs = epochs\n",
        "        self.weights = None\n",
        "        self.bias = None\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-z)) #SIgmoid function\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        self.weights = np.random.randn(n_features) * 0.01   #Initialize weights randomly\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in tqdm(range(self.epochs), desc=\"Training Progress\", unit=\"epoch\"):\n",
        "            # Compute linear combination\n",
        "            linear_model = np.dot(X, self.weights) + self.bias  # =w.x + b\n",
        "            y_pred = self.sigmoid(linear_model) #Applying sigmoid function\n",
        "\n",
        "            # Compute gradients and apply gradient descent\n",
        "            dw = (1 / n_samples) * np.dot(X.T, (y_pred - y))\n",
        "            db = (1 / n_samples) * np.sum(y_pred - y)\n",
        "\n",
        "            # Updating weights\n",
        "            self.weights -= self.alpha * dw\n",
        "            self.bias -= self.alpha * db\n",
        "\n",
        "    def predict_proba(self, X):\n",
        "        linear_model = np.dot(X, self.weights) + self.bias\n",
        "        return self.sigmoid(linear_model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int) #Returns 0 or 1 depending on predict_probability\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l2ZuyfW1TtS4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "url = \"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data_10_percent.gz\"\n",
        "filename = \"kddcup.data_10_percent.gz\"\n",
        "urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Kt3MPZ7Wu_x",
        "outputId": "58a140cc-0fe0-4d17-8992-e875ae8515dd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('kddcup.data_10_percent.gz', <http.client.HTTPMessage at 0x7ca4aa8d1c90>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Data\n",
        "\n",
        "# Setting column names from dataset description\n",
        "columns = [\n",
        "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
        "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
        "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
        "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
        "    \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\",\n",
        "    \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\",\n",
        "    \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
        "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
        "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
        "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"label\"\n",
        "]\n",
        "\n",
        "# Loading dataset in dataframe using pandas\n",
        "df = pd.read_csv(filename, names=columns)\n",
        "\n",
        "# Convert categorical columns using Label Encoding\n",
        "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
        "encoder = LabelEncoder()\n",
        "for col in categorical_cols:\n",
        "    df[col] = encoder.fit_transform(df[col])\n",
        "\n",
        "# Converting labels to binary, ie, 0 if normal and 1 if attack\n",
        "df[\"label\"] = df[\"label\"].apply(lambda x: 0 if x == \"normal.\" else 1)\n",
        "\n",
        "X = df.drop(\"label\", axis=1).values # Extracting features\n",
        "y = df[\"label\"].values #Extracting labels\n",
        "\n",
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "\n",
        "# 80% train, 20% test dataset split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "fdFnxv4SXPWJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the logistic regression model\n",
        "log_reg = LogisticRegression(alpha=0.01, epochs=1000)\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = np.mean(y_pred == y_test) * 100\n",
        "print(f\"Model Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d29GkPyXVmf",
        "outputId": "0ab6e4aa-2205-4295-81b8-7796e32435a3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training Progress: 100%|██████████| 1000/1000 [00:52<00:00, 19.00epoch/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 98.87%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}